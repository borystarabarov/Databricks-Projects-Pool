{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Parquet Files to Delta Table\n",
    "This notebook reads Parquet files as a stream and writes them to a Delta table with schema evolution enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showRowCount": true,
     "rowLimit": 1000
    }
   },
   "outputs": [],
   "source": [
    "# Configure spark to allow schema merging\n",
    "spark.conf.set(\"spark.sql.streaming.schemaInference\", True)\n",
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showRowCount": true,
     "rowLimit": 1000
    }
   },
   "outputs": [],
   "source": [
    "# Read the streaming parquet files\n",
    "stream_df = spark.readStream.format(\"parquet\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .load(\"abfss://external-location@databricksdevstgacc.dfs.core.windows.net/files2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showRowCount": true,
     "rowLimit": 1000
    }
   },
   "outputs": [],
   "source": [
    "# Write the stream to a delta table\n",
    "checkpoint_path = \"abfss://external-location@databricksdevstgacc.dfs.core.windows.net/checkpoints/stream_test\"\n",
    "\n",
    "stream_query = stream_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_path) \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .trigger(availableNow=True) \\\n",
    "    .toTable(\"dev_catalog.default.stream_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showRowCount": true,
     "rowLimit": 1000
    }
   },
   "outputs": [],
   "source": [
    "# Wait for the stream to complete\n",
    "stream_query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
